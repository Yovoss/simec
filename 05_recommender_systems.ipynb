{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SimEc for recommender systems\n",
    "Tasks like product recommendation or drug-target interaction prediction essentially consist of having to predict missing entries in a large matrix containing pairwise relations, e.g., the user ratings of some items or whether or not a drug interacts with a certain protein. Besides the sparse matrix containing the pairwise relations, generally one can also construct some feature vectors for the items and users (drugs / proteins), e.g., based on textual descriptions. These can come in especially handy when predictions need to be made, e.g., for new items that did not receive any user ratings so far. In the following we will only talk about items and users but of course this extends to other problem setups as well like drug-target interaction prediction. We distinguish between 3 tasks with increasing difficulty:\n",
    "- **T1**: Predict missing ratings for existing items and users\n",
    "- **T2a** and **T2b**: Predict ratings for new items and existing users (a) or new users and existing items (b)\n",
    "- **T3**: Predict ratings for new items and new users\n",
    "\n",
    "For tasks T2a/b and T3, feature vectors describing items and/or users are required. \n",
    "\n",
    "There are several methods that can be used to solve some or all of the above tasks. These include:\n",
    "##### Baseline Methods\n",
    "- **Predict average**: This is a no-brainer: simply fill all the missing values by averages. For example, an item rating from a user can be predicted based on the average rating the user usually gives (he might in general be more or less critical than other users) and the average rating the item got from other users (it might be better or worse than the average item) or for new items and users just predict the overall average rating (solves **T1, T2a/b, T3**).\n",
    "- **SVD of the ratings matrix**: By factorizing the ratings matrix using (iterative) singular value decomposition (SVD), one can compute a low rank approximation of the ratings matrix and use these approximate values as predictions for the missing values (solves **T1**). This can also be combined with the average ratings from above, i.e., the low rank approximation can be used to predict the residuals.\n",
    "- **SVD + Regression**: Given some feature vectors for items or users and the low rank approximation of the ratings matrix computed above, using a regression model, the mapping from the items' feature vectors to their rating vectors can be learned (or respectively for users). This is an extension of the above method to additionally solve either **T2a** or **T2b**, or **T3** if models are learned for both sides of the factorization.\n",
    "- **Regression/Classification model**: This approach is completely different from the so-called latent factor models discussed above. Here we train an ordinary regression or classification model (depending on the form of the pairwise data, e.g. continuous ratings or binary interactions) by using as input the concatenation of the feature vectors of an item and a user and as the target their rating. One possible realization of such a model could involve two neural networks to map the individual feature vectors into some lower dimensional embedding space. This approach can be used to solve all tasks **T1, T2a/b, T3** provided corresponding feature vectors are available.\n",
    "\n",
    "##### Similarity Encoder Models\n",
    "- **Factorization of the ratings matrix using the identity matrix as input**: By training a SimEc to factorize the ratings matrix using the identity matrix as input, we can recreate the solution obtained with SVD (while possibly better handling missing values when computing the decomposition). Correspondingly, this only solves **T1**.\n",
    "- **Factorization of the ratings matrix using feature vectors as input**: By using either item or user feature vectors as input when factorizing the ratings matrix, we can additionally solve **T2a** or **T2b**.\n",
    "- **Train a second SimEc with feature vectors and fixed last layer weights**: After training, e.g., a SimEc with item feature vectors as input to decompose the ratings matrix, we can use this SimEc to compute the item embeddings $Y$. We can then construct a second SimEc, which uses user feature vectors as input to factorize the ratings matrix. However, here we fix the weights of the last layer by setting them to the transpose of the embedding matrix computed for the items. After this SimEc is trained, we can now use both SimEcs to compute item and user embeddings respectively and then compute the scalar product of the embedding vectors to predict the ratings. This approach can then also be used to predict the ratings given the feature vectors for new items and users, i.e., it can be used to solve all tasks **T1, T2a/b, T3**.\n",
    "\n",
    "If the rating matrix contains explicit ratings (i.e. likes and dislikes), all available entries can be used to train the above models. If the pairwise relations in the matrix only represent implicit feedback or binary interactions (e.g. the user listens to music by certain artists, which means he likes them, but we don't know if he doesn't listen to other artists because he doesn't know them or because he doesn't like them), then we can use the given entries in the matrix as positive examples and additionally take a random sample of the missing entries and use them as negative examples. In the latter case, it might be more useful to use classification instead of regression models and also when training the SimEc it could be helpful to apply a non-linearity on the output before computing the error of the model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "In this notebook we work with the [movielens dataset](https://grouplens.org/datasets/movielens/10m/) and additionally pull some information about the individual movies from [the movie database](https://api.themoviedb.org/) using their API.\n",
    "\n",
    "Since we only have additional information about the movies, not the users, we focus on solving tasks **T1** and **T2a** here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:03.175525Z",
     "start_time": "2018-06-04T20:11:02.033864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzi/anaconda2/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, division, print_function, absolute_import\n",
    "from builtins import range, str\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "np.random.seed(28)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(28)\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.sparse import lil_matrix, dok_matrix, csr_matrix, hstack, vstack, diags\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge as rreg\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from simec import SimilarityEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:03.227050Z",
     "start_time": "2018-06-04T20:11:03.176650Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/recsys/tmdb_data\"):\n",
    "    os.mkdir(\"data/recsys/tmdb_data\")\n",
    "\n",
    "def parse_tmdb(tmdbid, apikey):\n",
    "    movie_data = {}\n",
    "    if os.path.exists(\"data/recsys/tmdb_data/%r.json\" % tmdbid):\n",
    "        with open(\"data/recsys/tmdb_data/%r.json\" % tmdbid) as f:\n",
    "            movie_data = json.load(f)\n",
    "    # for a movie with tmdbid get:\n",
    "    # genres:name, original language en y/n, id, title, overview, release_date-->year,\n",
    "    # keywords:keywords:name, credits:cast:name[:10], credits:crew:(\"job\": \"Director\"):name\n",
    "    if not movie_data:\n",
    "        r = requests.get(\"https://api.themoviedb.org/3/movie/%r?api_key=%s&language=en-US&append_to_response=keywords,credits\" % (tmdbid, apikey))\n",
    "        if r.status_code != 200:\n",
    "            print(\"something went wrong when accessing tmdb with id %r!\" % tmdbid)\n",
    "            print(r.text)\n",
    "        else:\n",
    "            movie_json = r.json()\n",
    "            movie_data['tmdbid'] = movie_json['id']\n",
    "            movie_data['title'] = movie_json['title']\n",
    "            movie_data['overview'] = movie_json['overview']\n",
    "            movie_data['release_date'] = movie_json['release_date']\n",
    "            movie_data['year'] = movie_json[\"release_date\"].split(\"-\")[0]\n",
    "            movie_data['original_en'] = str(movie_json['original_language'] == \"en\")\n",
    "            movie_data['genres'] = [g[\"name\"] for g in movie_json['genres']]\n",
    "            movie_data['keywords'] = [k[\"name\"] for k in movie_json['keywords']['keywords']]\n",
    "            movie_data['cast'] = [c[\"name\"] for c in movie_json['credits']['cast'][:10]]\n",
    "            movie_data['directors'] = [c[\"name\"] for c in movie_json['credits']['crew'] if c[\"job\"] == \"Director\"]\n",
    "            print(\"got data for %s\" % movie_json['title'])\n",
    "            with open(\"data/recsys/tmdb_data/%r.json\" % tmdbid, \"w\") as f:\n",
    "                json.dump(movie_data, f, indent=2)\n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:03.997402Z",
     "start_time": "2018-06-04T20:11:03.771130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got data for 10608 movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzi/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# get movielens data from: https://grouplens.org/datasets/movielens/10m/\n",
    "# load all possible movies (in the 10m dataset)\n",
    "df_movies = pd.read_csv(\"data/recsys/ml-10M100K/movies.dat\", sep=\"::\", names=[\"movieId\",\"title\",\"genres\"])\n",
    "# get corresponding tmdbids (only in 20m dataset)\n",
    "df_links = pd.read_csv(\"data/recsys/ml-20m/links.csv\")\n",
    "df_links = df_links.dropna()\n",
    "df_links = df_links.astype(int) \n",
    "map_movieids = dict(zip(df_links.movieId, df_links.tmdbId))\n",
    "# get additional details from themoviedb.org (assumes api key is stored at data/recsys/tmdb_apikey.txt)\n",
    "if os.path.exists(\"data/recsys/tmdb_data.json\"):\n",
    "    with open(\"data/recsys/tmdb_data.json\") as f:\n",
    "        movies_data = json.load(f)\n",
    "else:\n",
    "    movies_data = {}\n",
    "    with open('data/recsys/tmdb_apikey.txt') as f:\n",
    "        apikey = f.read().strip()\n",
    "    for movieid in df_movies.movieId:\n",
    "        if movieid in map_movieids:\n",
    "            m = parse_tmdb(map_movieids[movieid], apikey)\n",
    "            if m:\n",
    "                # careful: when loading the json later the ids will be strings as well anyways\n",
    "                movies_data[str(movieid)] = m\n",
    "            else:\n",
    "                print(\"error with movie id: %i\" % movieid)\n",
    "    with open(\"data/recsys/tmdb_data.json\", \"w\") as f:\n",
    "        json.dump(movies_data, f, indent=2)\n",
    "print(\"got data for %i movies\" % len(movies_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:38.639085Z",
     "start_time": "2018-06-04T20:11:04.637967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed 0 lines\n",
      "parsed 1000000 lines\n",
      "parsed 2000000 lines\n",
      "parsed 3000000 lines\n",
      "parsed 4000000 lines\n",
      "parsed 5000000 lines\n",
      "parsed 6000000 lines\n",
      "parsed 7000000 lines\n",
      "parsed 8000000 lines\n",
      "parsed 9000000 lines\n",
      "parsed 10000000 lines\n",
      "10604 movies, 69878 users, and 9989664 ratings\n"
     ]
    }
   ],
   "source": [
    "# load pairwise data and generate a dict with {(movieid, userid): rating}\n",
    "movieids = set()\n",
    "userids = set()\n",
    "tuple_ratings = {}\n",
    "rating_pairs = []\n",
    "with open(\"data/recsys/ml-10M100K/ratings.dat\") as f:\n",
    "    for i, l in enumerate(f.readlines()):\n",
    "        if not i % 1000000:\n",
    "            print(\"parsed %i lines\" % i)\n",
    "        u, m, r, t = l.strip().split(\"::\")\n",
    "        # only consider ratings for movies where we have external data available\n",
    "        if m in movies_data:\n",
    "            # in addition to the ratings, also get a list of all users and movies\n",
    "            if u not in userids:\n",
    "                userids.add(u)\n",
    "            if m not in movieids:\n",
    "                movieids.add(m)\n",
    "            tuple_ratings[(m,u)] = float(r)\n",
    "            rating_pairs.append((m,u))\n",
    "        #else:\n",
    "        #    print(\"warning, skipping rating for movie with id %r\" % m)\n",
    "# shuffle all movie and user ids (important so we can split data into train and test sets)\n",
    "# this list additionally functions as a mapping from a (matrix) index to the actual id\n",
    "np.random.seed(13)\n",
    "map_index2movieid = np.random.permutation(sorted(movieids))\n",
    "map_index2userid = np.random.permutation(sorted(userids))\n",
    "# also get a shuffeled list of all rating pairs\n",
    "rating_pairs = np.random.permutation(rating_pairs)\n",
    "print(\"%i movies, %i users, and %i ratings\" % (len(movieids), len(userids), len(rating_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Prediction\n",
    "#### Overview of prediction results (RMSE)\n",
    "\n",
    "|  | mean | mean+SVD | mean+SimEc(I) | mean+SVD+regression | mean+SimEc(X) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| **T1** | 0.88614 | **0.85891** | 0.87836 | 0.88025 | 0.86800 |\n",
    "| **T2a** | 0.97610 | - | - | 0.97340 | **0.96889** |\n",
    "\n",
    "While the SVD of the residual ratings matrix gives the best approximation of the ratings for known movies and users (T1), learning the connection between the movies' feature vectors and the pairwise relations with a SimEc enables us to make better prediction for new movies (T2a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:38.729021Z",
     "start_time": "2018-06-04T20:11:38.640290Z"
    }
   },
   "outputs": [],
   "source": [
    "# we have different scenarios: either we're only missing some individual ratings or entire movies/users\n",
    "def split_traintest(scenario):\n",
    "    print(\"generating train/test splits for scenario %r\" % scenario)\n",
    "    if scenario == \"T1\":\n",
    "        # missing ratings\n",
    "        rating_pairs_train = rating_pairs[:int(0.7*len(rating_pairs))]\n",
    "        rating_pairs_test = rating_pairs[int(0.7*len(rating_pairs)):]\n",
    "        map_index2movieid_train = map_index2movieid\n",
    "        map_index2userid_train = map_index2userid\n",
    "    else:\n",
    "        rating_pairs_train = []\n",
    "        rating_pairs_test = []\n",
    "        if scenario == \"T2a\":\n",
    "            # missing movies\n",
    "            map_index2movieid_train = map_index2movieid[:int(0.7*len(map_index2movieid))]\n",
    "            map_index2userid_train = map_index2userid\n",
    "        elif scenario == \"T2b\":\n",
    "            # missing users\n",
    "            map_index2movieid_train = map_index2movieid\n",
    "            map_index2userid_train = map_index2userid[:int(0.7*len(map_index2userid))]\n",
    "        elif scenario == \"T3\":\n",
    "            # missing movies and users\n",
    "            map_index2movieid_train = map_index2movieid[:int(0.85*len(map_index2movieid))]\n",
    "            map_index2userid_train = map_index2userid[:int(0.8*len(map_index2userid))]\n",
    "        else:\n",
    "            raise Exception(\"unknown scenario %r, use either T1, T2a, T2b, or T3!\" % scenario)\n",
    "        movieids_train_set = set(map_index2movieid_train)\n",
    "        userids_train_set = set(map_index2userid_train)\n",
    "        rating_pairs_train = []\n",
    "        rating_pairs_test = []\n",
    "        for (m, u) in rating_pairs:\n",
    "            if u in userids_train_set and m in movieids_train_set:\n",
    "                rating_pairs_train.append((m, u))\n",
    "            else:\n",
    "                rating_pairs_test.append((m, u))\n",
    "    print(\"got %i training and %i test ratings\" % (len(rating_pairs_train), len(rating_pairs_test)))\n",
    "    # create mappings from the actual id to the index\n",
    "    map_movieid2index_train = {m: i for i, m in enumerate(map_index2movieid_train)}\n",
    "    map_userid2index_train = {u: i for i, u in enumerate(map_index2userid_train)}\n",
    "    return rating_pairs_train, rating_pairs_test, map_index2userid_train,\\\n",
    "           map_index2movieid_train, map_userid2index_train, map_movieid2index_train\n",
    "\n",
    "def make_train_matrix(tuple_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train):\n",
    "    # transform training ratings into a sparse matrix for convenience\n",
    "    print(\"transforming dict with %i ratings into sparse matrix\" % len(rating_pairs_train))\n",
    "    ratings_matrix = lil_matrix((len(map_movieid2index_train),len(map_userid2index_train)))\n",
    "    for (m, u) in rating_pairs_train:\n",
    "        ratings_matrix[map_movieid2index_train[m],map_userid2index_train[u]] = tuple_ratings[(m, u)]\n",
    "    ratings_matrix = csr_matrix(ratings_matrix)\n",
    "    return ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: predict mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:11:38.799777Z",
     "start_time": "2018-06-04T20:11:38.730287Z"
    }
   },
   "outputs": [],
   "source": [
    "class MeansModel():\n",
    "    \"\"\"\n",
    "    A very simple baseline model, which predicts the rating a user would give to a movie as:\n",
    "        mean + user_mean + movie_mean\n",
    "    \"\"\"\n",
    "    def __init__(self, shrinkage=1.):\n",
    "        self.mean = None\n",
    "        self.mean_users = {}\n",
    "        self.mean_movies = {}\n",
    "        # shrinkage decreases the influence of the individual user/movie means\n",
    "        # --> mean + shrinkage*user_mean + shrinkage*movie_mean\n",
    "        # it should always be between 0 and 1; 0 means individual means are ignored\n",
    "        self.shrinkage = max(0., min(1., shrinkage))\n",
    "\n",
    "    def fit(self, tuple_ratings, rating_pairs_train):\n",
    "        # overall mean based on all training ratings\n",
    "        self.mean = np.mean([tuple_ratings[(m, u)] for (m, u) in rating_pairs_train])\n",
    "        # means for movies and users\n",
    "        if self.shrinkage:\n",
    "            mean_users = defaultdict(list)\n",
    "            mean_movies = defaultdict(list)\n",
    "            for (m, u) in rating_pairs_train:\n",
    "                mean_users[u].append(tuple_ratings[(m, u)])\n",
    "                mean_movies[m].append(tuple_ratings[(m, u)])\n",
    "            self.mean_users = {u: np.mean(mean_users[u])-self.mean for u in mean_users}\n",
    "            self.mean_movies = {m: np.mean(mean_movies[m])-self.mean for m in mean_movies}\n",
    "    \n",
    "    def predict(self, m, u, residuals=None):\n",
    "        \"\"\"\n",
    "        generate rating prediction for a user u and movie m\n",
    "        \"\"\"\n",
    "        rating = self.mean\n",
    "        if u in self.mean_users:\n",
    "            rating += self.shrinkage*self.mean_users[u]\n",
    "        if m in self.mean_movies:\n",
    "            rating += self.shrinkage*self.mean_movies[m]\n",
    "        if residuals and (m, u) in residuals:\n",
    "            rating += residuals[(m, u)]\n",
    "        return rating\n",
    "    \n",
    "    def compute_residuals(self, tuple_ratings, rating_pairs_train):\n",
    "        \"\"\"\n",
    "        for all ratings, subtract the respective average ratings to get residuals\n",
    "        \"\"\"\n",
    "        return {(m, u): tuple_ratings[(m, u)] - (self.mean+self.shrinkage*(self.mean_users[u]+self.mean_movies[m]))\n",
    "                                  for (m, u) in rating_pairs_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:35:00.361240Z",
     "start_time": "2018-06-02T11:23:33.231973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T1: RMSE: 1.06044; MAE: 0.85552\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T1: RMSE: 1.02330; MAE: 0.82574\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T1: RMSE: 0.91333; MAE: 0.71937\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T1: RMSE: 0.88074; MAE: 0.68157\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T1: RMSE: 0.88614; MAE: 0.68404\n",
      "generating train/test splits for scenario 'T2a'\n",
      "got 7064138 training and 2925526 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T2a: RMSE: 1.05938; MAE: 0.85143\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T2a: RMSE: 1.04342; MAE: 0.83821\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T2a: RMSE: 0.99569; MAE: 0.79322\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T2a: RMSE: 0.97628; MAE: 0.76558\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T2a: RMSE: 0.97610; MAE: 0.76332\n",
      "generating train/test splits for scenario 'T2b'\n",
      "got 7015197 training and 2974467 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T2b: RMSE: 1.05763; MAE: 0.85382\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T2b: RMSE: 1.03627; MAE: 0.83724\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T2b: RMSE: 0.97058; MAE: 0.77542\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T2b: RMSE: 0.94101; MAE: 0.73810\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T2b: RMSE: 0.93976; MAE: 0.73544\n",
      "generating train/test splits for scenario 'T3'\n",
      "got 6827065 training and 3162599 test ratings\n",
      "fitting model with shrinkage=0.0\n",
      "Scenario T3: RMSE: 1.05580; MAE: 0.85198\n",
      "fitting model with shrinkage=0.1\n",
      "Scenario T3: RMSE: 1.03854; MAE: 0.83850\n",
      "fitting model with shrinkage=0.5\n",
      "Scenario T3: RMSE: 0.98629; MAE: 0.78893\n",
      "fitting model with shrinkage=0.9\n",
      "Scenario T3: RMSE: 0.96390; MAE: 0.75888\n",
      "fitting model with shrinkage=1.0\n",
      "Scenario T3: RMSE: 0.96327; MAE: 0.75657\n"
     ]
    }
   ],
   "source": [
    "for scenario in [\"T1\", \"T2a\", \"T2b\", \"T3\"]:\n",
    "    # get train/test data\n",
    "    rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "    for shrinkage in [0., 0.1, 0.5, 0.9, 1.]:\n",
    "        # initalize means model\n",
    "        mmodel = MeansModel(shrinkage)\n",
    "        print(\"fitting model with shrinkage=%.1f\" % shrinkage)\n",
    "        mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "        # get a vector with target ratings for test tuples\n",
    "        y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "        # get the corresponding predictions\n",
    "        y_pred = np.array([mmodel.predict(m, u) for (m, u) in rating_pairs_test])\n",
    "        print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: SVD of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:13:53.109332Z",
     "start_time": "2018-06-04T20:11:38.801292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing residuals\n",
      "transforming dict with 6992764 ratings into sparse matrix\n"
     ]
    }
   ],
   "source": [
    "scenario = \"T1\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:39:32.812757Z",
     "start_time": "2018-06-02T11:37:16.045751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'eigenvalue')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc88f9fb6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect eigenvalues of matrix\n",
    "eigenvals = svds(ratings_matrix, k=1000, return_singular_vectors=False)\n",
    "eigenvals = sorted(eigenvals, reverse=True)\n",
    "plt.figure()\n",
    "plt.plot(list(range(1, len(eigenvals)+1)), eigenvals)\n",
    "plt.xlabel(\"eigenvalue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:39:45.041235Z",
     "start_time": "2018-06-02T11:39:32.814347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10604, 100), (100, 100), (100, 69878))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get eigenvalues and -vectors for some relevant dimensions\n",
    "e_dim = 100\n",
    "U, s, Vh = svds(ratings_matrix, k=e_dim)\n",
    "S = np.zeros((e_dim, e_dim))\n",
    "S = np.diag(s)\n",
    "U.shape, S.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:40:15.660247Z",
     "start_time": "2018-06-02T11:39:45.042808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.85891; MAE: 0.65994\n"
     ]
    }
   ],
   "source": [
    "# construct approximation of residual ratings\n",
    "print(\"get approximations\")\n",
    "temp = np.dot(U, np.dot(S, Vh))\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimEc model: identity matrix as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:25:17.718289Z",
     "start_time": "2018-06-04T20:13:53.110906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0073\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.87836; MAE: 0.67734\n"
     ]
    }
   ],
   "source": [
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# train simec with identiy matrix as input to predict residuals\n",
    "e_dim = 100\n",
    "X = np.eye(ratings_matrix.shape[0], dtype=np.float16)\n",
    "model = SimilarityEncoder(ratings_matrix.shape[0], e_dim, ratings_matrix.shape[1], opt=0.05)\n",
    "model.fit(X, ratings_matrix, epochs=20)\n",
    "print(\"get approximations\")\n",
    "temp = np.array(model.predict(X), dtype=np.float16)\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct feature vectors for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:28:40.048296Z",
     "start_time": "2018-06-04T20:28:39.984588Z"
    }
   },
   "outputs": [],
   "source": [
    "def features2mat(movies_data, movieids, feature, featurenames=[]):\n",
    "    if not featurenames:\n",
    "        featurenames = sorted(set(word for m in movieids for word in movies_data[m][feature]))\n",
    "    fnamedict = {feat: i for i, feat in enumerate(featurenames)}\n",
    "    featmat = dok_matrix((len(movieids), len(featurenames)), dtype=np.float16)\n",
    "    for i, m in enumerate(movieids):\n",
    "        for word in movies_data[m][feature]:\n",
    "            try:\n",
    "                featmat[i, fnamedict[word]] = 1.\n",
    "            except KeyError:\n",
    "                pass\n",
    "    featmat = csr_matrix(featmat)\n",
    "    return featmat, featurenames\n",
    "\n",
    "def get_features_mats(movieids_train, movieids_test):\n",
    "    featurenames = []\n",
    "    genres_mat_train, genres_names = features2mat(movies_data, movieids_train, \"genres\")\n",
    "    featurenames.extend(genres_names)\n",
    "    genres_mat_test, _ = features2mat(movies_data, movieids_test, \"genres\", genres_names)\n",
    "    keywords_mat_train, keywords_names = features2mat(movies_data, movieids_train, \"keywords\")\n",
    "    featurenames.extend(keywords_names)\n",
    "    keywords_mat_test, _ = features2mat(movies_data, movieids_test, \"keywords\", keywords_names)\n",
    "    directors_mat_train, directors_names = features2mat(movies_data, movieids_train, \"directors\")\n",
    "    featurenames.extend(directors_names)\n",
    "    directors_mat_test, _ = features2mat(movies_data, movieids_test, \"directors\", directors_names)\n",
    "    feat_mat_train = hstack([genres_mat_train, keywords_mat_train, directors_mat_train], format=\"csr\", dtype=np.float16)\n",
    "    feat_mat_test = hstack([genres_mat_test, keywords_mat_test, directors_mat_test], format=\"csr\", dtype=np.float16)\n",
    "    return feat_mat_train, feat_mat_test, featurenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model: SVD of residuals with regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:55:02.756452Z",
     "start_time": "2018-06-02T11:51:57.792262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing residuals\n",
      "transforming dict with 6992764 ratings into sparse matrix\n",
      "train regression model\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.88025; MAE: 0.67904\n"
     ]
    }
   ],
   "source": [
    "## for T1 same scenario as above\n",
    "scenario = \"T1\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "# train and test movies are the same, i.e., no unknown movies\n",
    "feat_mat_train, _, _ = get_features_mats(map_index2movieid_train, [])\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)\n",
    "# get eigenvalues and -vectors for some relevant dimensions\n",
    "e_dim = 100\n",
    "U, s, Vh = svds(ratings_matrix, k=e_dim)\n",
    "S = np.zeros((e_dim, e_dim))\n",
    "S = np.diag(s)\n",
    "# train regression model to map from feat_mat to U\n",
    "print(\"train regression model\")\n",
    "alpha = 250.  # None to do grid search\n",
    "if alpha is None:\n",
    "    m = rreg()\n",
    "    rrm = GridSearchCV(m, {'alpha': [0.01, 0.1, 0.25, 0.5, 0.75, 1., 2.5 , 5., 7.5, 10., 25., 50., 75., 100., 250., 500., 750., 1000.]})\n",
    "    rrm.fit(feat_mat_train, U)\n",
    "    print(\"best alpha: \", rrm.best_params_)\n",
    "else:\n",
    "    rrm = rreg(alpha=alpha)\n",
    "    rrm.fit(feat_mat_train, U)\n",
    "U_pred = rrm.predict(feat_mat_train)\n",
    "# construct approximation of residual ratings\n",
    "print(\"get approximations\")\n",
    "temp = np.dot(U_pred, np.dot(S, Vh))\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T11:57:38.045193Z",
     "start_time": "2018-06-02T11:55:02.758295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T2a'\n",
      "got 7064138 training and 2925526 test ratings\n",
      "computing residuals\n",
      "transforming dict with 7064138 ratings into sparse matrix\n",
      "train regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzi/anaconda2/envs/python36/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T2a: RMSE: 0.97340; MAE: 0.76115\n"
     ]
    }
   ],
   "source": [
    "scenario = \"T2a\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "movieids_test = sorted(set(m for (m, u) in rating_pairs_test if m not in map_movieid2index_train))\n",
    "map_movieid2index_all = {m : i for i, m in enumerate(movieids_test, len(map_movieid2index_train))}\n",
    "map_movieid2index_all.update(map_movieid2index_train)\n",
    "feat_mat_train, feat_mat_test, _ = get_features_mats(map_index2movieid_train, movieids_test)\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)\n",
    "# get eigenvalues and -vectors for some relevant dimensions\n",
    "e_dim = 100\n",
    "U, s, Vh = svds(ratings_matrix, k=e_dim)\n",
    "S = np.zeros((e_dim, e_dim))\n",
    "S = np.diag(s)\n",
    "# train regression model to map from feat_mat to U\n",
    "print(\"train regression model\")\n",
    "rrm = rreg(alpha=250.)\n",
    "rrm.fit(feat_mat_train, U)\n",
    "# stack train and test feature matrices to make predictions for all\n",
    "feat_mat_all = vstack([feat_mat_train, feat_mat_test], format=\"csr\", dtype=np.float16)\n",
    "del feat_mat_train, feat_mat_test\n",
    "U_pred = rrm.predict(feat_mat_all)\n",
    "# construct approximation of residual ratings\n",
    "print(\"get approximations\")\n",
    "temp = np.dot(U_pred, np.dot(S, Vh))\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_all[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimEc model: feature matrix as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:43:29.748476Z",
     "start_time": "2018-06-04T20:29:52.262896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing residuals\n",
      "transforming dict with 6992764 ratings into sparse matrix\n",
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0073\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0072\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0071\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 32s 3ms/step - loss: 0.0071\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T1: RMSE: 0.86800; MAE: 0.66852\n"
     ]
    }
   ],
   "source": [
    "## for T1 same scenario as above\n",
    "scenario = \"T1\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "# train and test movies are the same, i.e., no unknown movies\n",
    "feat_mat_train, _, _ = get_features_mats(map_index2movieid_train, [])\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# train simec with identiy matrix as input to predict residuals\n",
    "e_dim = 100\n",
    "model = SimilarityEncoder(feat_mat_train.shape[1], e_dim, ratings_matrix.shape[1], sparse_inputs=True,\n",
    "                          opt=0.0075)\n",
    "model.fit(feat_mat_train, ratings_matrix, epochs=20)\n",
    "print(\"get approximations\")\n",
    "temp = np.array(model.predict(feat_mat_train), dtype=np.float16)\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_train[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T20:57:18.352425Z",
     "start_time": "2018-06-04T20:47:22.308813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T2a'\n",
      "got 7064138 training and 2925526 test ratings\n",
      "computing residuals\n",
      "transforming dict with 7064138 ratings into sparse matrix\n",
      "Epoch 1/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0104\n",
      "Epoch 2/20\n",
      "7422/7422 [==============================] - 22s 3ms/step - loss: 0.0104\n",
      "Epoch 3/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0104\n",
      "Epoch 4/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0103\n",
      "Epoch 5/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0103\n",
      "Epoch 6/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0103\n",
      "Epoch 7/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0102\n",
      "Epoch 8/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0102\n",
      "Epoch 9/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0101\n",
      "Epoch 10/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0101\n",
      "Epoch 11/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0101\n",
      "Epoch 12/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0100\n",
      "Epoch 13/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0100\n",
      "Epoch 14/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0099\n",
      "Epoch 15/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0099\n",
      "Epoch 16/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0099\n",
      "Epoch 17/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0098\n",
      "Epoch 18/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0098\n",
      "Epoch 19/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0097\n",
      "Epoch 20/20\n",
      "7422/7422 [==============================] - 23s 3ms/step - loss: 0.0097\n",
      "get approximations\n",
      "get residual ratings\n",
      "predict test ratings\n",
      "Scenario T2a: RMSE: 0.96889; MAE: 0.75740\n"
     ]
    }
   ],
   "source": [
    "scenario = \"T2a\"\n",
    "# get train/test data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(scenario)\n",
    "movieids_test = sorted(set(m for (m, u) in rating_pairs_test if m not in map_movieid2index_train))\n",
    "map_movieid2index_all = {m : i for i, m in enumerate(movieids_test, len(map_movieid2index_train))}\n",
    "map_movieid2index_all.update(map_movieid2index_train)\n",
    "feat_mat_train, feat_mat_test, _ = get_features_mats(map_index2movieid_train, movieids_test)\n",
    "# stack train and test feature matrices to make predictions for all\n",
    "feat_mat_all = vstack([feat_mat_train, feat_mat_test], format=\"csr\", dtype=np.float16)\n",
    "del feat_mat_test\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)\n",
    "# get a vector with target ratings for test tuples\n",
    "y_true = np.array([tuple_ratings[(m, u)] for (m, u) in rating_pairs_test])\n",
    "# train simec with identiy matrix as input to predict residuals\n",
    "e_dim = 100\n",
    "model = SimilarityEncoder(feat_mat_train.shape[1], e_dim, ratings_matrix.shape[1], sparse_inputs=True,\n",
    "                          opt=0.005)\n",
    "model.fit(feat_mat_train, ratings_matrix, epochs=20)\n",
    "print(\"get approximations\")\n",
    "temp = np.array(model.predict(feat_mat_all), dtype=np.float16)\n",
    "# get dict with residuals for missing test ratings\n",
    "print(\"get residual ratings\")\n",
    "residual_ratings_test = {(m, u): temp[map_movieid2index_all[m], map_userid2index_train[u]]\n",
    "                                 for (m, u) in rating_pairs_test}\n",
    "del temp\n",
    "print(\"predict test ratings\")\n",
    "# get the corresponding predictions\n",
    "y_pred = np.array([mmodel.predict(m, u, residual_ratings_test) for (m, u) in rating_pairs_test])\n",
    "print(\"Scenario %s: RMSE: %.5f; MAE: %.5f\" % (scenario, np.sqrt(mean_squared_error(y_true, y_pred)), mean_absolute_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of ratings\n",
    "\n",
    "In addition to accurately predicting a user's rating for a certain item and therefore generating valuable recommendations, it might also be interesting to understand _why_ a user might like a certain item. For this, we can use [_layerwise relevance propagation_](http://heatmapping.org/) to identify the features of an item that most contributed to a positive or negative predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:21:42.668958Z",
     "start_time": "2018-06-02T12:21:42.624967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6755 Bubba Ho-tep\n",
      "51498 2001 Maniacs\n",
      "48678 Feast\n",
      "44777 Evil Aliens\n",
      "1115 The Sleepover\n",
      "54910 Behind the Mask: The Rise of Leslie Vernon\n",
      "62008 Dead Fury\n",
      "32314 Incident at Loch Ness\n",
      "7846 Tremors 3: Back to Perfection\n",
      "5478 Eight Legged Freaks\n",
      "60522 The Machine Girl\n",
      "60044 Baghead\n",
      "8578 Undead\n",
      "27563 The Happiness of the Katakuris\n",
      "32239 Save the Green Planet!\n",
      "7266 The Lost Skeleton of Cadavra\n",
      "48231 Taxidermia\n",
      "7202 Beyond Re-Animator\n",
      "44828 Slither\n",
      "57910 Teeth\n",
      "32011 Cursed\n",
      "8874 Shaun of the Dead\n",
      "5837 Legion of the Dead\n",
      "47937 Severance\n",
      "60363 Zombie Strippers!\n",
      "8258 Citizen Toxie: The Toxic Avenger IV\n",
      "4996 Little Otik\n",
      "7319 Club Dread\n",
      "5909 Visitor Q\n",
      "53468 Fido\n",
      "55553 Black Sheep\n"
     ]
    }
   ],
   "source": [
    "# select an interesting movies that appeals to different kinds of audiences\n",
    "# e.g. 8874 Shaun of the Dead\n",
    "for mid in movies_data:\n",
    "    if \"Comedy\" in movies_data[mid][\"genres\"] and \"Horror\" in movies_data[mid][\"genres\"] and movies_data[mid][\"year\"] > \"2000\":\n",
    "        print(mid, movies_data[mid][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:25:29.811983Z",
     "start_time": "2018-06-02T12:21:42.672042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3817 4159\n",
      "14134 2750\n",
      "38928 2552\n",
      "43992 2444\n",
      "67542 2333\n",
      "33399 2257\n",
      "24695 2235\n",
      "55005 2176\n",
      "57481 2129\n",
      "30977 2110\n",
      "18278 1886\n",
      "69714 1863\n",
      "63905 1804\n",
      "6845 1662\n",
      "41391 1597\n",
      "54922 1582\n",
      "3810 1560\n",
      "36827 1512\n",
      "9181 1473\n",
      "3022 1424\n",
      "44041 1406\n",
      "37412 1396\n",
      "9139 1381\n",
      "16992 1368\n",
      "12367 1361\n",
      "23988 1333\n",
      "48717 1291\n",
      "19111 1205\n",
      "28855 1195\n",
      "35015 1191\n",
      "18692 1149\n",
      "36585 1138\n",
      "18870 1125\n",
      "42242 1121\n",
      "27313 1088\n",
      "55433 1079\n",
      "34324 1077\n",
      "70116 1076\n",
      "30275 1070\n",
      "59934 1051\n",
      "35779 1047\n",
      "23733 1045\n",
      "60100 1044\n",
      "47579 1033\n",
      "3171 1028\n",
      "32501 1013\n",
      "41130 1005\n",
      "18717 1002\n",
      "8930 987\n",
      "41394 969\n",
      "16963 965\n",
      "37430 964\n",
      "49009 949\n",
      "66543 949\n",
      "1854 915\n",
      "7678 913\n",
      "5226 908\n",
      "64718 902\n",
      "61141 883\n",
      "8683 881\n",
      "66519 880\n",
      "48933 855\n",
      "31152 845\n",
      "11638 837\n",
      "29268 831\n",
      "19669 823\n",
      "38373 819\n",
      "3336 818\n",
      "48919 812\n",
      "28128 808\n",
      "16163 800\n",
      "1771 798\n",
      "1805 775\n",
      "38322 775\n",
      "30493 765\n",
      "10799 764\n",
      "28460 756\n",
      "62293 753\n",
      "46956 745\n",
      "50311 741\n",
      "57862 736\n",
      "16058 735\n",
      "35105 733\n",
      "44500 731\n",
      "43364 728\n",
      "70332 723\n",
      "52610 720\n",
      "68986 720\n",
      "29218 714\n",
      "25502 705\n",
      "48842 698\n",
      "70516 687\n",
      "65949 684\n",
      "40234 683\n",
      "66795 678\n",
      "12207 675\n",
      "23485 675\n",
      "28645 674\n",
      "64063 673\n",
      "69490 673\n",
      "22712 670\n",
      "53480 661\n",
      "26152 659\n",
      "20306 649\n",
      "57567 639\n",
      "8097 638\n",
      "22104 637\n",
      "29483 635\n",
      "36913 635\n",
      "29097 633\n",
      "42241 629\n",
      "46931 627\n",
      "1139 623\n",
      "68516 623\n",
      "31837 616\n",
      "62854 616\n",
      "62784 615\n",
      "71331 613\n",
      "6941 611\n",
      "67325 610\n",
      "24770 604\n",
      "14140 598\n",
      "29701 596\n",
      "49186 594\n",
      "61079 582\n",
      "29375 578\n",
      "3977 577\n",
      "15259 575\n",
      "55945 569\n",
      "34011 568\n",
      "18616 564\n",
      "28492 562\n",
      "24560 555\n",
      "55773 552\n",
      "19066 546\n",
      "27115 541\n",
      "54912 541\n",
      "46257 536\n",
      "31228 533\n",
      "39272 527\n",
      "70489 524\n",
      "35133 522\n",
      "31807 521\n",
      "67968 521\n",
      "14240 520\n",
      "34101 519\n",
      "70278 517\n",
      "1858 512\n",
      "64423 512\n",
      "12781 509\n",
      "5716 503\n",
      "64717 502\n",
      "3595 501\n",
      "31503 501\n",
      "49913 500\n",
      "65358 500\n",
      "39214 499\n",
      "41404 490\n",
      "52000 487\n",
      "10313 486\n",
      "34429 485\n",
      "57526 482\n",
      "45991 480\n",
      "5667 477\n",
      "13271 468\n",
      "1440 466\n",
      "5954 466\n",
      "25197 465\n",
      "29039 464\n",
      "49865 463\n",
      "70617 463\n",
      "23634 461\n",
      "249 460\n",
      "35368 458\n",
      "60462 456\n",
      "64225 456\n",
      "43487 455\n",
      "33285 454\n",
      "46836 451\n",
      "38744 450\n",
      "7217 449\n",
      "61941 445\n",
      "20492 439\n",
      "26599 437\n",
      "55453 434\n",
      "59577 433\n",
      "26842 430\n",
      "65947 426\n",
      "13852 423\n",
      "46030 423\n",
      "57829 422\n",
      "61505 421\n",
      "16858 413\n",
      "26060 410\n",
      "47767 409\n",
      "46416 407\n",
      "65353 406\n",
      "22944 405\n",
      "48068 405\n",
      "2435 404\n",
      "37750 402\n",
      "35386 401\n",
      "27459 399\n",
      "20084 397\n",
      "22331 395\n",
      "37000 395\n",
      "46069 395\n",
      "18628 394\n",
      "67124 393\n",
      "24395 391\n",
      "11841 388\n",
      "27475 387\n",
      "47226 387\n",
      "60538 383\n",
      "54200 380\n",
      "50892 377\n",
      "18179 374\n",
      "47119 374\n",
      "21371 370\n",
      "59994 370\n",
      "17632 369\n",
      "67645 369\n",
      "28847 364\n",
      "2414 363\n",
      "62112 359\n",
      "9618 358\n",
      "27264 356\n",
      "51494 356\n",
      "41859 355\n",
      "481 353\n",
      "57814 353\n",
      "62868 351\n",
      "61386 350\n",
      "42884 348\n",
      "38480 347\n",
      "38917 347\n",
      "27806 345\n",
      "64906 345\n",
      "34489 344\n",
      "31895 341\n",
      "32332 341\n",
      "35835 340\n",
      "51512 340\n",
      "44413 337\n",
      "44639 331\n",
      "28315 330\n",
      "62842 330\n",
      "55590 328\n",
      "50850 325\n",
      "60381 325\n",
      "5396 324\n",
      "34895 322\n",
      "46684 321\n",
      "57946 318\n",
      "70543 317\n",
      "50139 315\n",
      "5546 314\n",
      "2434 309\n",
      "46327 308\n",
      "14593 305\n",
      "45852 305\n",
      "39580 304\n",
      "39985 303\n",
      "17520 302\n",
      "20064 300\n",
      "65154 297\n",
      "19116 296\n",
      "20908 296\n",
      "15958 295\n",
      "36822 295\n",
      "279 294\n",
      "17243 294\n",
      "25717 294\n",
      "30988 294\n",
      "545 292\n",
      "40085 289\n",
      "67871 289\n",
      "68624 288\n",
      "24680 287\n",
      "13014 286\n",
      "8574 281\n",
      "37217 281\n",
      "64194 279\n",
      "7728 278\n",
      "30697 278\n",
      "34677 278\n",
      "28637 277\n",
      "57065 277\n",
      "5886 275\n",
      "63088 272\n",
      "36217 269\n",
      "61342 269\n",
      "67258 269\n",
      "34918 268\n",
      "53057 267\n",
      "70057 267\n",
      "14528 266\n",
      "42641 266\n",
      "49151 266\n",
      "48274 264\n",
      "17749 263\n",
      "52376 260\n",
      "17433 259\n",
      "30931 259\n",
      "39184 259\n",
      "37594 258\n",
      "46899 258\n",
      "62033 258\n",
      "63721 258\n",
      "27696 255\n",
      "37125 255\n",
      "67867 253\n",
      "30708 251\n",
      "65205 251\n",
      "41343 250\n",
      "52155 249\n",
      "49055 248\n",
      "30347 247\n",
      "52892 247\n",
      "60102 247\n",
      "4459 246\n",
      "70032 245\n",
      "1077 244\n",
      "52648 243\n",
      "25354 241\n",
      "28677 240\n",
      "15130 239\n",
      "70889 236\n",
      "10372 234\n",
      "3917 233\n",
      "13466 233\n",
      "41665 233\n",
      "46413 233\n",
      "43742 232\n",
      "14498 230\n",
      "22684 230\n",
      "34927 230\n",
      "4258 229\n",
      "509 228\n",
      "8215 227\n",
      "66687 226\n",
      "6431 225\n",
      "18016 222\n",
      "55781 222\n",
      "57905 221\n",
      "44880 219\n",
      "1090 216\n",
      "12818 216\n",
      "18244 216\n",
      "36893 213\n",
      "15049 209\n",
      "67021 209\n",
      "40301 207\n",
      "31845 205\n",
      "49935 205\n",
      "9127 204\n",
      "19992 204\n",
      "34087 203\n",
      "40928 203\n",
      "36994 198\n",
      "57966 193\n",
      "39047 191\n",
      "21888 189\n",
      "51668 189\n",
      "54727 188\n",
      "1849 187\n",
      "6064 182\n",
      "60652 182\n",
      "26734 181\n",
      "48287 181\n",
      "15950 180\n",
      "45909 180\n",
      "64127 179\n",
      "12281 178\n",
      "51662 178\n",
      "64254 178\n",
      "44979 176\n",
      "34621 175\n",
      "5687 174\n",
      "56043 173\n",
      "26229 172\n",
      "30115 171\n",
      "31364 171\n",
      "42006 171\n",
      "46142 171\n",
      "48106 171\n",
      "8402 170\n",
      "7860 167\n",
      "69687 167\n",
      "62357 166\n",
      "902 165\n",
      "38739 165\n",
      "23342 163\n",
      "27540 163\n",
      "51164 163\n",
      "39030 162\n",
      "17350 160\n",
      "30423 160\n",
      "52565 160\n",
      "64379 159\n",
      "65578 159\n",
      "27509 158\n",
      "50983 157\n",
      "64019 157\n",
      "28175 156\n",
      "69297 155\n",
      "70374 153\n",
      "56524 151\n",
      "69039 147\n",
      "36775 146\n",
      "34189 144\n",
      "45992 144\n",
      "55168 143\n",
      "32968 142\n",
      "55378 142\n",
      "59263 142\n",
      "29429 141\n",
      "32041 140\n",
      "7247 139\n",
      "11571 139\n",
      "20231 137\n",
      "35994 134\n",
      "28856 133\n",
      "39275 133\n",
      "32931 132\n",
      "35784 132\n",
      "58510 130\n",
      "13771 129\n",
      "58895 129\n",
      "59433 129\n",
      "62448 129\n",
      "67089 129\n",
      "13448 123\n",
      "65702 123\n",
      "41778 122\n",
      "51904 122\n",
      "65127 122\n",
      "69802 122\n",
      "71300 122\n",
      "25342 121\n",
      "32662 121\n",
      "53274 121\n",
      "54891 121\n",
      "52640 120\n",
      "20915 116\n",
      "55343 115\n",
      "2665 114\n",
      "43555 114\n",
      "52041 114\n",
      "67901 114\n",
      "3611 113\n",
      "40095 112\n",
      "55157 112\n",
      "4918 110\n",
      "29731 109\n",
      "36488 109\n",
      "46940 109\n",
      "66655 108\n",
      "48904 107\n",
      "55383 106\n",
      "665 104\n",
      "41556 104\n",
      "62126 103\n",
      "22113 102\n",
      "70430 100\n",
      "28718 99\n",
      "35385 99\n",
      "55573 99\n",
      "66602 99\n",
      "50175 98\n",
      "37050 95\n",
      "8653 94\n",
      "60115 94\n",
      "6873 92\n",
      "39049 92\n",
      "22991 91\n",
      "1656 90\n",
      "5236 90\n",
      "22413 90\n",
      "52925 90\n",
      "57164 90\n",
      "49195 87\n",
      "11436 86\n",
      "43694 86\n",
      "25996 85\n",
      "52393 85\n",
      "50337 84\n",
      "2753 83\n",
      "63774 83\n",
      "3006 82\n",
      "35017 81\n",
      "48440 80\n",
      "48455 78\n",
      "66491 78\n",
      "21327 77\n",
      "49696 76\n",
      "20320 75\n",
      "29825 74\n",
      "4833 72\n",
      "22753 72\n",
      "43208 72\n",
      "1903 71\n",
      "20210 71\n",
      "52714 71\n",
      "53192 71\n",
      "57425 71\n",
      "66764 71\n",
      "21904 70\n",
      "44373 70\n",
      "58703 66\n",
      "8838 65\n",
      "57127 65\n",
      "43276 64\n",
      "56181 64\n",
      "12416 63\n",
      "14171 62\n",
      "14479 62\n",
      "34185 62\n",
      "37583 62\n",
      "62209 61\n",
      "50418 60\n",
      "27578 59\n",
      "27284 57\n",
      "18145 56\n",
      "57997 56\n",
      "64566 56\n",
      "8498 55\n",
      "59399 54\n",
      "9683 53\n",
      "33278 53\n",
      "1263 52\n",
      "34648 52\n",
      "23627 51\n",
      "53257 51\n",
      "69241 51\n",
      "18269 50\n",
      "55533 50\n",
      "37390 49\n",
      "60952 49\n",
      "11582 48\n",
      "34293 48\n",
      "55408 48\n",
      "38676 47\n",
      "69956 46\n",
      "37203 44\n",
      "30076 43\n",
      "43784 42\n",
      "70550 42\n",
      "48162 41\n",
      "69779 39\n",
      "10883 38\n",
      "64972 38\n",
      "41266 36\n",
      "30849 35\n",
      "42373 29\n",
      "2866 26\n",
      "53813 26\n",
      "26896 24\n"
     ]
    }
   ],
   "source": [
    "# check which users have given the movie a 5 star rating\n",
    "users = []\n",
    "for (m, u) in tuple_ratings:\n",
    "    if m == \"8874\" and tuple_ratings[(m, u)] >= 5:\n",
    "        users.append(u)\n",
    "# sort these users by the most ratings\n",
    "users = {u: len([1 for (m, x) in tuple_ratings if u==x]) for u in users}\n",
    "for u in sorted(users, key=users.get, reverse=True):\n",
    "    print(u, users[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:25:30.696955Z",
     "start_time": "2018-06-02T12:25:29.818221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horror 122\n",
      "Comedy 106\n",
      "Thriller 100\n",
      "Drama 76\n",
      "Mystery 46\n",
      "Action 46\n",
      "Science Fiction 41\n",
      "Crime 36\n",
      "Adventure 35\n",
      "Romance 30\n",
      "Fantasy 23\n",
      "Family 12\n",
      "Music 4\n",
      "Western 2\n",
      "War 2\n",
      "Documentary 2\n",
      "History 1\n"
     ]
    }
   ],
   "source": [
    "# check which genres the users like the most\n",
    "# Horror is high ranked\n",
    "genres = []\n",
    "for (m, u) in residual_ratings:\n",
    "    if u == \"3817\" and residual_ratings[(m, u)] >= 1:\n",
    "        genres.extend(movies_data[m][\"genres\"])\n",
    "genres = Counter(genres)\n",
    "for g in sorted(genres, key=genres.get, reverse=True):\n",
    "    print(g, genres[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:25:31.563638Z",
     "start_time": "2018-06-02T12:25:30.700055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama 157\n",
      "Comedy 104\n",
      "Thriller 55\n",
      "Romance 53\n",
      "Crime 49\n",
      "Action 34\n",
      "Adventure 26\n",
      "Mystery 23\n",
      "Fantasy 17\n",
      "History 17\n",
      "War 16\n",
      "Horror 15\n",
      "Science Fiction 12\n",
      "Documentary 12\n",
      "Western 9\n",
      "Music 9\n",
      "Family 9\n",
      "Animation 4\n",
      "TV Movie 1\n"
     ]
    }
   ],
   "source": [
    "# check which genres the users like the most\n",
    "# Comedy is high ranked, Horror scores low\n",
    "genres = []\n",
    "for (m, u) in residual_ratings:\n",
    "    if u == \"14134\" and residual_ratings[(m, u)] >= 1:\n",
    "        genres.extend(movies_data[m][\"genres\"])\n",
    "genres = Counter(genres)\n",
    "for g in sorted(genres, key=genres.get, reverse=True):\n",
    "    print(g, genres[g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:51:07.189669Z",
     "start_time": "2018-06-02T12:25:31.565932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing residuals\n",
      "transforming dict with 9989664 ratings into sparse matrix\n",
      "Epoch 1/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0104\n",
      "Epoch 2/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0103\n",
      "Epoch 3/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0103\n",
      "Epoch 4/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0103\n",
      "Epoch 5/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0103\n",
      "Epoch 6/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0102\n",
      "Epoch 7/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0102\n",
      "Epoch 8/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0102\n",
      "Epoch 9/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0102\n",
      "Epoch 10/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0101\n",
      "Epoch 11/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0101\n",
      "Epoch 12/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0101\n",
      "Epoch 13/40\n",
      "10604/10604 [==============================] - 34s 3ms/step - loss: 0.0101\n",
      "Epoch 14/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0101\n",
      "Epoch 15/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0100\n",
      "Epoch 16/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0100\n",
      "Epoch 17/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0100\n",
      "Epoch 18/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0100\n",
      "Epoch 19/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0099\n",
      "Epoch 20/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0099\n",
      "Epoch 21/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0099\n",
      "Epoch 22/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0099\n",
      "Epoch 23/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0098\n",
      "Epoch 24/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0098\n",
      "Epoch 25/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0098\n",
      "Epoch 26/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0098\n",
      "Epoch 27/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0098\n",
      "Epoch 28/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 29/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 30/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 31/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 32/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 33/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0097\n",
      "Epoch 34/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 35/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 36/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 37/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 38/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 39/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n",
      "Epoch 40/40\n",
      "10604/10604 [==============================] - 33s 3ms/step - loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "## train a simec model on all the data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(\"T1\")\n",
    "rating_pairs_train, rating_pairs_test = list(rating_pairs_train), list(rating_pairs_test)\n",
    "rating_pairs_train.extend(rating_pairs_test)\n",
    "feat_mat_train, _, featurenames = get_features_mats(map_index2movieid_train, [])\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing residuals\")\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "ratings_matrix = make_train_matrix(residual_ratings, rating_pairs_train, map_userid2index_train, map_movieid2index_train)\n",
    "# get dense ratings matrix with missing values = -100\n",
    "R = -100*np.ones(ratings_matrix.shape, dtype=np.float16)\n",
    "R[ratings_matrix.nonzero()] = ratings_matrix[ratings_matrix.nonzero()]\n",
    "# train simec with identiy matrix as input to predict residuals\n",
    "e_dim = 100\n",
    "model = SimilarityEncoder(feat_mat_train.shape[1], e_dim, ratings_matrix.shape[1], sparse_inputs=True,\n",
    "                          mask_value=-100, opt=0.005)\n",
    "model.fit(feat_mat_train, ratings_matrix, epochs=40)\n",
    "del R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:51:08.593949Z",
     "start_time": "2018-06-02T12:51:07.191419Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5081229063347688 1.6716881864501811\n",
      "[[0.36489856 0.02659127]]\n",
      "0.3648987300693989 0.026591266272589564\n"
     ]
    }
   ],
   "source": [
    "# for a certain movie, create a new feature matrix with the features on the diagonal\n",
    "# to get relevancy scores for each separate feature (only works for linear SimEc)\n",
    "m = \"8874\"\n",
    "u1 = \"3817\"\n",
    "u2 = \"14134\"\n",
    "mid = map_movieid2index_train[m]\n",
    "uid1 = map_userid2index_train[u1]\n",
    "uid2 = map_userid2index_train[u2]\n",
    "# check regular prediction scores\n",
    "print(residual_ratings[(m,u1)], residual_ratings[(m,u2)])\n",
    "print(model.predict(feat_mat_train[mid,:])[:,[uid1, uid2]])\n",
    "f_movie = csr_matrix(diags(feat_mat_train[mid,:].toarray()[0], 0, shape=(feat_mat_train.shape[1], feat_mat_train.shape[1])))\n",
    "# featurewise predictions need to be corrected for the bias\n",
    "temp = np.dot((model.transform(f_movie) + (1/f_movie.count_nonzero() - 1.) * model.model.layers[1].get_weights()[1]), model.model.layers[2].get_weights()[0][:, [uid1, uid2]])\n",
    "uid1_scores = {f: temp[i,0] for i, f in enumerate(featurenames) if f_movie[i,i]}\n",
    "uid2_scores = {f: temp[i,1] for i, f in enumerate(featurenames) if f_movie[i,i]}\n",
    "del temp\n",
    "# this should be the same as the original predictions\n",
    "print(sum(uid1_scores.values()), sum(uid2_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:51:08.617325Z",
     "start_time": "2018-06-02T12:51:08.595522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3648987300693989 5.0 1.5081229063347688\n",
      "Horror 0.12818159\n",
      "british pub 0.052393153\n",
      "pub 0.04612521\n",
      "cult film 0.03864223\n",
      "survival horror 0.026523238\n",
      "Comedy 0.020480556\n",
      "surrey 0.019219069\n",
      "Edgar Wright 0.016725892\n",
      "zombie 0.016607787\n"
     ]
    }
   ],
   "source": [
    "# the Horror afine user seems to like this move mostly because it's a horror movie\n",
    "print(sum(uid1_scores.values()), tuple_ratings[(m, u1)], residual_ratings[(m, u1)])\n",
    "for f in sorted(uid1_scores, key=uid1_scores.get, reverse=True):\n",
    "    print(f, uid1_scores[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T12:51:08.652849Z",
     "start_time": "2018-06-02T12:51:08.618978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026591266272589564 5.0 1.6716881864501811\n",
      "Edgar Wright 0.022943476\n",
      "british pub 0.020250771\n",
      "cult film 0.019522961\n",
      "Comedy 0.011469547\n",
      "pub 0.0047876565\n",
      "surrey 0.002977433\n",
      "survival horror -0.0040684626\n",
      "Horror -0.016388858\n",
      "zombie -0.034903258\n"
     ]
    }
   ],
   "source": [
    "# the comedy user likes it because it's a comedy cult film and zombie and Horror score negatively\n",
    "print(sum(uid2_scores.values()), tuple_ratings[(m, u2)], residual_ratings[(m, u2)])\n",
    "for f in sorted(uid2_scores, key=uid2_scores.get, reverse=True):\n",
    "    print(f, uid2_scores[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content based recommendations\n",
    "In the following, we discuss recommendations on item basis, e.g., suggesting similar items alongside an item a user is currently looking at. With content based recommendations, these suggestions are made based on the items' features, not the user ratings, which means that suggestions can also be made for new items that did not receive any ratings yet. However, a similarity score computed straight from the items' feature vectors does not correspond well to what users perceive as similar items, e.g., movies that got similar ratings from users are not necessarily similar with respect to their feature vectors.\n",
    "\n",
    "By using SimEc to learn a mapping from the items' feature vectors into an embedding space where the user ratings based similarities are preserved, more useful suggestions can be generated even for new items. By first projecting the item's feature vector in the embedding space and then computing the dot product with all other items' embedding vectors, the most similar items can be identified and recommended alongside the item of interest:\n",
    "<img src=\"data/simec_recommendation.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:00:04.001513Z",
     "start_time": "2018-06-02T14:55:53.815704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating train/test splits for scenario 'T1'\n",
      "got 6992764 training and 2996900 test ratings\n",
      "computing content based similarities\n",
      "16 movies have no features...:/\n",
      "computing user ratings based similarities\n",
      "Correlation between ratings: 0.10173558715473119 0.05280107092262353\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d9626eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "rating_pairs_train, rating_pairs_test, map_index2userid_train, map_index2movieid_train, map_userid2index_train, map_movieid2index_train = split_traintest(\"T1\")\n",
    "rating_pairs_train, rating_pairs_test = list(rating_pairs_train), list(rating_pairs_test)\n",
    "rating_pairs_train.extend(rating_pairs_test)\n",
    "# get feature vectors for all movies\n",
    "print(\"computing content based similarities\")\n",
    "feat_mat_train, _, featurenames = get_features_mats(map_index2movieid_train, [])\n",
    "# normalize them to have length 1 (since features are binary, norm is just the sqrt(sum()))\n",
    "N = np.sqrt(feat_mat_train.sum(1))\n",
    "print(\"%i movies have no features...:/\" % np.sum(N==0))\n",
    "N[N==0] = 1\n",
    "feat_mat_train_normed = feat_mat_train/N\n",
    "# compute content based similarity matrix (\"similar movies have similar genres/directors/topics\")\n",
    "S_content = feat_mat_train_normed.dot(feat_mat_train_normed.T).A  # cosine similarity\n",
    "# get sparse matrix with residuals\n",
    "print(\"computing user ratings based similarities\")\n",
    "# initalize and fit means model\n",
    "mmodel = MeansModel()\n",
    "mmodel.fit(tuple_ratings, rating_pairs_train)\n",
    "residual_ratings = mmodel.compute_residuals(tuple_ratings, rating_pairs_train)\n",
    "# transform residual_ratings into a dict with {movieid: {userid: rating}}\n",
    "residual_ratings_movies = defaultdict(dict)\n",
    "for (m, u) in residual_ratings:\n",
    "    residual_ratings_movies[m][u] = residual_ratings[(m, u)]\n",
    "# normalize rating vectors to have unit length\n",
    "for m in residual_ratings_movies:\n",
    "    N = np.linalg.norm(list(residual_ratings_movies[m].values())) \n",
    "    residual_ratings_movies[m] = {u: residual_ratings_movies[m][u]/N for u in residual_ratings_movies[m]}\n",
    "# transform into sparse matrix\n",
    "ratings_matrix = dok_matrix((len(map_movieid2index_train), len(map_userid2index_train)), dtype=float)\n",
    "for i, m in enumerate(map_index2movieid_train):\n",
    "    for u in residual_ratings_movies[m]:\n",
    "        ratings_matrix[i, map_userid2index_train[u]] = residual_ratings_movies[m][u]\n",
    "ratings_matrix = csr_matrix(ratings_matrix)\n",
    "# compute user ratings based similarity matrix (\"similar movies get similar ratings\")\n",
    "S_user = ratings_matrix.dot(ratings_matrix.T).A\n",
    "# check correlation between both similarity scores (--> if movies with similar content also \n",
    "# get similar ratings, the content based similarity score can be used for recommendations)\n",
    "s_content_flat = np.asarray(S_content[np.triu_indices_from(S_content)])\n",
    "s_user_flat = np.asarray(S_user[np.triu_indices_from(S_user)])\n",
    "corr_pear = pearsonr(s_content_flat, s_user_flat)[0]\n",
    "corr_spear = spearmanr(s_content_flat, s_user_flat)[0]\n",
    "print(\"Correlation between ratings:\", corr_pear, corr_spear)\n",
    "ridx = np.random.permutation(len(s_content_flat))[:5000]\n",
    "plt.figure()\n",
    "plt.scatter(s_user_flat[ridx], s_content_flat[ridx], s=2)\n",
    "plt.xlabel(\"user ratings similarities\")\n",
    "plt.ylabel(\"content similarities\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T17:59:21.566772Z",
     "start_time": "2018-06-02T17:50:20.562555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0100\n",
      "Epoch 2/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0078\n",
      "Epoch 3/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0077\n",
      "Epoch 4/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0077\n",
      "Epoch 5/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0077\n",
      "Epoch 6/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0077\n",
      "Epoch 7/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0077\n",
      "Epoch 8/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 9/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 10/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 11/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 12/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 13/20\n",
      "10604/10604 [==============================] - 26s 2ms/step - loss: 0.0076\n",
      "Epoch 14/20\n",
      "10604/10604 [==============================] - 26s 2ms/step - loss: 0.0076\n",
      "Epoch 15/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 16/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 17/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 18/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 19/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "Epoch 20/20\n",
      "10604/10604 [==============================] - 25s 2ms/step - loss: 0.0076\n",
      "[ 1.         -0.0026715  -0.01689782 -0.01024931  0.04311016 -0.01997239]\n",
      "[ 0.03272194 -0.00334606  0.00241135 -0.00140673  0.03903061  0.00385103]\n",
      "[ 0.02098764 -0.00862237  0.00104268  0.00045342  0.03530704  0.0037037 ]\n",
      "Correlation between ratings: 0.4864058932013009 0.4216686367576709\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b603b9128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train a simec to map the movie feature vectors into an embedding space,\n",
    "# where the user rating based similarities are preserved\n",
    "e_dim = 100\n",
    "n_targets = 1000\n",
    "model = SimilarityEncoder(feat_mat_train.shape[1], e_dim, n_targets, [(500, \"tanh\")], sparse_inputs=True, opt=0.001,\n",
    "                          s_ll_reg=10., S_ll=S_user[:n_targets, :n_targets])\n",
    "model.fit(feat_mat_train, S_user[:, :n_targets], epochs=20)\n",
    "# compute embeddings for movies\n",
    "X_embed = model.transform(feat_mat_train)\n",
    "# compute simec similarity and check correlation\n",
    "print (S_user[0,:6])\n",
    "print (model.predict(feat_mat_train)[0,:6])\n",
    "S_simec = X_embed.dot(X_embed.T)\n",
    "print (S_simec[0,:6])\n",
    "s_simec_flat = np.asarray(S_simec[np.triu_indices_from(S_simec)])\n",
    "corr_pear = pearsonr(s_simec_flat, s_user_flat)[0]\n",
    "corr_spear = spearmanr(s_simec_flat, s_user_flat)[0]\n",
    "print(\"Correlation between ratings:\", corr_pear, corr_spear)\n",
    "plt.figure()\n",
    "plt.scatter(s_user_flat[ridx], s_simec_flat[ridx], s=2)\n",
    "plt.xlabel(\"user ratings similarities\")\n",
    "plt.ylabel(\"simec similarities\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
